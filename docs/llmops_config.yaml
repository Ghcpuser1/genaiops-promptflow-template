
# <azure_config>
# Azure Subscription, Azure ML workspace and Keyvault comfiguration details.
# values specified in ${<env_var>} are loaded from environment variables 
  azure_config:
    subscription_id: ${SUBSCRIPTION_ID}
    resource_group_name: ${RESOURCE_GROUP_NAME}
    workspace_name: ${WORKSPACE_NAME}
    keyvault_name: ${KEYVAULT_NAME}
    compute_target: ${COMPUTE_TARGET}

# <connections>
# Promptflow connections for Azure OpenAI, OpenAI and others
# values specified in ${<env_var>} are loaded from environment variables.
  - connection: aoai
    api_type: azure
    api_key: ${AZURE_OPENAI_KEY}
    api_base: ${AZURE_OPENAI_ENDPOINT}
    api_version: ${AZURE_OPENAI_API_VERSION}

# experiment
# <name>
# Defines the experiment name which is: 
#   1. Used as the experiment name of Azure ML jobs.
#   2. Used as the name of the model when it is registered in Azure ML.

name: <experiment_name>

# <flow>
# Defines the standard flow of the experiment. 
# If the variable is not set, the experiment name is used. 
# If it is set, it should be the path to the folder containing the Prompt Flow files
# (including flow.dag.yaml).
#
# Note: It is recommended to keep all flow folders (standard and evaluators) in a 
# common "flows" folder. If that structure is used, the name of the flow folder can 
# can be used as the flow_name instead of the path to it. The library will 
# automatically check the flows directory (i.e., "flows/<flow_name>") first to 
# look for the standard flow.

flow: <flow_name>

# <datasets>
# Defines the datasets used for the standard flow in this experiment.
# Each dataset listed will be used to run the standard flow; it can also be used
# to run one or more of the evaluation flows (see below). 
# If the dataset is referencing a local dataset, it will be uploaded to Azure ML.
#
# Properties of a dataset. 
# - name: the unique name used to reference the dataset.
#   source: reference to an existing dataset in Azure ML <azureml:$name:$version> or path to local dataset.
#   description: description used for the dataset when uploaded to Azure ML. Optional, only 
#         used when source is set to a path of a local file.
#   mappings: the mapping from the input of the standard Prompt Flow flow, to the column
#          name of the dataset where the input will be read from. Must use syntax 
#          `${data.<column_name>}`.

datasets:
- name: <dataset_0_name>
  source: azureml:<dataset_name>:<dataset_version>
  mappings:
    <flow_input_name>: "${data.<column_name>}"
- name: <dataset_1_name>
  source: ./path/to/data.jsonl
  description: "dataset description"
  mappings:
    <flow_input_name>: "${data.<column_name>}"

# <evaluators>
# Defines the evaluators used in the experiment. Each evaluator is a Prompt Flow flow. 
# Each evaluator requires a dataset. The dataset must already be defined above (meaning 
# it was used to run the standard flow) OR it must contain a reference to a dataset from
# above. The result of the standard flow with the matching dataset is used as input to 
# the evaluation flow.
# 
# Properties of an evaluator
# - name: the unique name used to reference the evaluator.
#   flow: the path to the flow folder. As noted above, the library will automatically
#         check the flows directory (i.e., "flows/<flow_name>") first to look for the
#         evaluator flow.
#   datasets:
#   - name: name of the dataset used. Must match the unique name of one of the datasets 
#         listed above, OR must have "source" and "reference" parameter and the "reference"
#         parameter must match the unique name of one of the datasets listed above.
#     source: reference to an existing dataset in Azure ML <azureml:$name:$version> or path 
#         to local dataset. Optional, only required when the "name" parameter doesn't match
#         any of the datasets listed above.
#     description: description used for the dataset when uploaded to Azure ML. Optional, only 
#         used when "source" is set to a path of a local file.
#     reference: name of the reference dataset. Must match the unique name of one of the 
#         datasets listed above.  Optional, only required when the "name" parameter doesn't 
#         match any of the datasets listed above.
#     mappings: the mapping from the input of the evaluation Prompt Flow flow, to the column
#         name of the dataset where the input will be read from OR to the output of the 
#         standard run using the same dataset. Must use syntax `${data.<column_name>}` or 
#         "${run.outputs.<output_name>}".

evaluators:
- name: <evaluator_0_name>
  datasets:
  - name: <dataset_0_name> # Note that "dataset_0_name" was already defined in the "datasets" block
    mappings:
      flow_input_0_name: "${data.<column_name>}"
      flow_input_1_name: "${run.outputs.<output_name>}"
- name: <evaluator_1_name>
  datasets:
  - name: <dataset_x_name> # Note that "dataset_x_name" is a new dataset
    source: azureml:<dataset_name>:<dataset_version> # or ./path/to/data.jsonl
    reference: <dataset_0_name> # Note that new datasets in the evaluation block must reference an already existing dataset
    mappings:
      flow_input_0_name: "${data.<column_name>}"
      flow_input_1_name: "${run.outputs.<output_name>}"

# <runtime>
# Defines the name of the Prompt Flow runtime to be used. If not specified, automatic runtime and serverless compute is used.
runtime: <runtime_name> 

# <environments>
# configuration for environments for ex: pr - Pull Request, Dev, Prod etc.
# experiment configuration entries override the base experiment configuration 

  dev:
    env_name: dev
    
    experiment:

# <deployment configuration>
# configured under each environment. deployment configuration parameters for azure managed endpoints, kubernetes endpoints, and web app endpoint
    deployment_configs:

# <azure_managed_endpoint>
# configuration for azure managed endpoints
      azure_managed_endpoint:
      - name: azure_managed_endpoint
        ENV_NAME: dev
        TEST_FILE_PATH: sample-request.json
        ENDPOINT_NAME: 
        ENDPOINT_DESC: An AML compute based endpoint serving a flow for web classification
        DEPLOYMENT_DESC: prompt flow deployment
        PRIOR_DEPLOYMENT_NAME: 
        PRIOR_DEPLOYMENT_TRAFFIC_ALLOCATION: "0"
        CURRENT_DEPLOYMENT_NAME:
        CURRENT_DEPLOYMENT_TRAFFIC_ALLOCATION: "100"
        DEPLOYMENT_VM_SIZE: Standard_E16s_v3
        DEPLOYMENT_INSTANCE_COUNT: 1
        ENVIRONMENT_VARIABLES: 
          example-name: example-value

# <kubernetes_endpoint>
# configuration for kubernetes endpoints      
      kubernetes_endpoint:
      - name: kubernetes_endpoint_1
        ENV_NAME: dev
        TEST_FILE_PATH: sample-request.json
        ENDPOINT_NAME:
        ENDPOINT_DESC: An kubernetes endpoint serving a flow for web classification
        DEPLOYMENT_DESC: prompt flow deployment
        PRIOR_DEPLOYMENT_NAME:
        PRIOR_DEPLOYMENT_TRAFFIC_ALLOCATION:
        CURRENT_DEPLOYMENT_NAME:
        CURRENT_DEPLOYMENT_TRAFFIC_ALLOCATION: 100,
        COMPUTE_NAME:
        DEPLOYMENT_VM_SIZE:
        DEPLOYMENT_INSTANCE_COUNT: 1
        CPU_ALLOCATION: 
        MEMORY_ALLOCATION: 
        ENVIRONMENT_VARIABLES: 
          example-name: example-value
          
# <webapp_endpoint>
# configuration for webapp endpoints            
      webapp_endpoint:
      - name: webapp_endpoint_1
        ENV_NAME: dev
        TEST_FILE_PATH: sample-request.json
        CONNECTION_NAMES:
          - aoai
        REGISTRY_NAME:
        REGISTRY_RG_NAME:
        APP_PLAN_NAME:
        WEB_APP_NAME:
        WEB_APP_RG_NAME:
        WEB_APP_SKU: "B3"
        USER_MANAGED_ID:
